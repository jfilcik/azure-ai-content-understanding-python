{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ff63c1",
   "metadata": {},
   "source": [
    "# Move Training Data Across Analyzers\n",
    "\n",
    "This notebook demonstrates how to reuse training data from an existing analyzer when creating a new analyzer in the same Azure AI Content Understanding resource.\n",
    "\n",
    "## Overview\n",
    "\n",
    "When you have an analyzer with training data and want to create a new analyzer using the same labeled examples, you can reference the existing blob storage location without duplicating or moving the data.\n",
    "\n",
    "### Benefits\n",
    "- **No data duplication**: Reuse existing training data without copying\n",
    "- **Same resource**: Both analyzers access the same blob storage\n",
    "- **Field portability**: Maintain stable `fieldId`s across analyzers\n",
    "- **Rapid iteration**: Test schema variations quickly\n",
    "\n",
    "### Prerequisites\n",
    "1. An existing analyzer with training data already configured\n",
    "2. Azure AI service configured by following the [configuration steps](../README.md#configure-azure-ai-service-resource)\n",
    "3. Required packages installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f76b866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: aiohttp in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 1)) (3.12.15)\n",
      "Requirement already satisfied: azure-identity in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 2)) (1.25.0)\n",
      "Requirement already satisfied: azure-storage-blob in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 3)) (12.26.0)\n",
      "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: requests in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 5)) (2.32.5)\n",
      "Requirement already satisfied: Pillow in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 6)) (11.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (1.20.1)\n",
      "Requirement already satisfied: aiohttp in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 1)) (3.12.15)\n",
      "Requirement already satisfied: azure-identity in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 2)) (1.25.0)\n",
      "Requirement already satisfied: azure-storage-blob in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 3)) (12.26.0)\n",
      "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: requests in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 5)) (2.32.5)\n",
      "Requirement already satisfied: Pillow in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 6)) (11.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp->-r ../requirements.txt (line 1)) (1.20.1)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 2)) (1.35.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 2)) (46.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 2)) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-storage-blob->-r ../requirements.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 5)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 5)) (2025.8.3)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 2)) (1.35.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 2)) (46.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 2)) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-storage-blob->-r ../requirements.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 5)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 5)) (2025.8.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.31.0->azure-identity->-r ../requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.31.0->azure-identity->-r ../requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity->-r ../requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r ../requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity->-r ../requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r ../requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity->-r ../requirements.txt (line 2)) (2.23)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity->-r ../requirements.txt (line 2)) (2.23)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0032373",
   "metadata": {},
   "source": [
    "## Create Azure AI Content Understanding Client\n",
    "\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class providing functions to interact with the Content Understanding API. Before the official release of the Content Understanding SDK, this acts as a lightweight SDK.\n",
    "\n",
    "> âš ï¸ **Important**: Update the code below to match your Azure authentication method. Look for the `# IMPORTANT` comments and modify those sections accordingly.\n",
    "\n",
    "> âš ï¸ **Note**: Using a subscription key works, but using a token provider with Azure Active Directory (AAD) is safer and highly recommended for production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcea7936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.identity._credentials.environment:No environment configuration found.\n",
      "INFO:azure.identity._credentials.managed_identity:ManagedIdentityCredential will use IMDS\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=REDACTED&resource=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'User-Agent': 'azsdk-python-identity/1.25.0 Python/3.11.13 (Linux-6.8.0-1030-azure-x86_64-with-glibc2.41)'\n",
      "No body was attached to the request\n",
      "INFO:azure.identity._credentials.managed_identity:ManagedIdentityCredential will use IMDS\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=REDACTED&resource=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'User-Agent': 'azsdk-python-identity/1.25.0 Python/3.11.13 (Linux-6.8.0-1030-azure-x86_64-with-glibc2.41)'\n",
      "No body was attached to the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 400\n",
      "Response headers:\n",
      "    'Content-Type': 'application/json; charset=utf-8'\n",
      "    'Server': 'IMDS/150.870.65.1854'\n",
      "    'x-ms-request-id': '7683a8fc-6110-4d17-ba92-e7986c8af8e0'\n",
      "    'Date': 'Wed, 22 Oct 2025 22:06:40 GMT'\n",
      "    'Content-Length': '88'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=REDACTED&resource=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'Metadata': 'REDACTED'\n",
      "    'User-Agent': 'azsdk-python-identity/1.25.0 Python/3.11.13 (Linux-6.8.0-1030-azure-x86_64-with-glibc2.41)'\n",
      "No body was attached to the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 400\n",
      "Response headers:\n",
      "    'Content-Type': 'application/json; charset=utf-8'\n",
      "    'Server': 'IMDS/150.870.65.1854'\n",
      "    'x-ms-request-id': '31ec0b5d-182f-4981-8624-34083dd1c063'\n",
      "    'Date': 'Wed, 22 Oct 2025 22:06:40 GMT'\n",
      "    'Content-Length': '68'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 400\n",
      "Response headers:\n",
      "    'Content-Type': 'application/json; charset=utf-8'\n",
      "    'Server': 'IMDS/150.870.65.1854'\n",
      "    'x-ms-request-id': '7683a8fc-6110-4d17-ba92-e7986c8af8e0'\n",
      "    'Date': 'Wed, 22 Oct 2025 22:06:40 GMT'\n",
      "    'Content-Length': '88'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=REDACTED&resource=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'Metadata': 'REDACTED'\n",
      "    'User-Agent': 'azsdk-python-identity/1.25.0 Python/3.11.13 (Linux-6.8.0-1030-azure-x86_64-with-glibc2.41)'\n",
      "No body was attached to the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 400\n",
      "Response headers:\n",
      "    'Content-Type': 'application/json; charset=utf-8'\n",
      "    'Server': 'IMDS/150.870.65.1854'\n",
      "    'x-ms-request-id': '31ec0b5d-182f-4981-8624-34083dd1c063'\n",
      "    'Date': 'Wed, 22 Oct 2025 22:06:40 GMT'\n",
      "    'Content-Length': '68'\n",
      "INFO:azure.identity._credentials.chained:DefaultAzureCredential acquired a token from AzureDeveloperCliCredential\n",
      "INFO:azure.identity._credentials.chained:DefaultAzureCredential acquired a token from AzureDeveloperCliCredential\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Content Understanding client initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# For authentication, you can use either token-based authentication or a subscription key; only one method is required.\n",
    "AZURE_AI_ENDPOINT = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    "# IMPORTANT: Replace with your actual subscription key or set it in the \".env\" file if not using token authentication.\n",
    "AZURE_AI_API_KEY = os.getenv(\"AZURE_AI_API_KEY\")\n",
    "AZURE_AI_API_VERSION = os.getenv(\"AZURE_AI_API_VERSION\", \"2025-05-01-preview\")\n",
    "\n",
    "# Add the parent directory to the path to use shared modules\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_ENDPOINT,\n",
    "    api_version=AZURE_AI_API_VERSION,\n",
    "    # IMPORTANT: Comment out token_provider if using subscription key\n",
    "    token_provider=token_provider,\n",
    "    # IMPORTANT: Uncomment this if using subscription key\n",
    "    # subscription_key=AZURE_AI_API_KEY,\n",
    "    x_ms_useragent=\"azure-ai-content-understanding-python/move_training_data\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Content Understanding client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e5f27f",
   "metadata": {},
   "source": [
    "## Step 1: List Available Analyzers\n",
    "\n",
    "First, let's see what analyzers are available in your resource. We'll look for analyzers that have training data configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all analyzers in your resource\n",
    "all_analyzers = client.get_all_analyzers()\n",
    "analyzers_list = all_analyzers.get('value', [])\n",
    "\n",
    "print(f\"Found {len(analyzers_list)} analyzer(s) in your resource\\n\")\n",
    "\n",
    "# Display analyzer names and IDs\n",
    "if analyzers_list:\n",
    "    print(\"Available analyzers:\")\n",
    "    for idx, analyzer in enumerate(analyzers_list, 1):\n",
    "        analyzer_id = analyzer.get('analyzerId', 'N/A')\n",
    "        analyzer_name = analyzer.get('name', 'N/A')\n",
    "        print(f\"{idx}. ID: {analyzer_id}\")\n",
    "        print(f\"   Name: {analyzer_name}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No analyzers found. Please create an analyzer with training data first.\")\n",
    "    print(\"See: notebooks/analyzer_training.ipynb for guidance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6ae2ac",
   "metadata": {},
   "source": [
    "## Step 2: Select Source Analyzer\n",
    "\n",
    "Specify the ID of the analyzer whose training data you want to reuse.\n",
    "\n",
    "**Option 1**: Set `SOURCE_ANALYZER_ID` to an existing analyzer ID from the list above.\n",
    "\n",
    "**Option 2**: If you don't have an analyzer with training data, uncomment and run the next cell to create one first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772b0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Analyzer ID: invoiceLabeledData\n"
     ]
    }
   ],
   "source": [
    "# OPTION 1: Specify an existing analyzer ID that has training data\n",
    "\n",
    "# âš ï¸ REQUIRED: Replace \"MyAnalyzer\" with your actual analyzer ID from the list above\n",
    "# You can find available analyzer IDs in the output of the previous cell\n",
    "SOURCE_ANALYZER_ID = \"MyAnalyzer\"  # â† CHANGE THIS!\n",
    "\n",
    "# Uncomment to use the first analyzer from the list\n",
    "# if analyzers_list:\n",
    "#     SOURCE_ANALYZER_ID = analyzers_list[0].get('id')\n",
    "#     print(f\"Using first analyzer: {SOURCE_ANALYZER_ID}\")\n",
    "\n",
    "print(f\"Source Analyzer ID: {SOURCE_ANALYZER_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ceffda",
   "metadata": {},
   "source": [
    "### Option 2: Create a Source Analyzer with Training Data (Optional)\n",
    "\n",
    "If you don't have an existing analyzer with training data, run this cell to create one first.\n",
    "\n",
    "**Prerequisites**:\n",
    "- Set environment variables for training data (see [docs/set_env_for_training_data_and_reference_doc.md](../docs/set_env_for_training_data_and_reference_doc.md))\n",
    "- Ensure you have labeled training data in `../data/document_training/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce228bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this entire cell if you need to create a source analyzer first\n",
    "\n",
    "# from azure.storage.blob import ContainerSasPermissions\n",
    "\n",
    "# # Configure training data\n",
    "# analyzer_template_path = \"../analyzer_templates/receipt.json\"\n",
    "# training_docs_folder = \"../data/document_training\"\n",
    "\n",
    "# # Get or generate SAS URL\n",
    "# training_data_sas_url = os.getenv(\"TRAINING_DATA_SAS_URL\")\n",
    "# if not training_data_sas_url:\n",
    "#     TRAINING_DATA_STORAGE_ACCOUNT_NAME = os.getenv(\"TRAINING_DATA_STORAGE_ACCOUNT_NAME\")\n",
    "#     TRAINING_DATA_CONTAINER_NAME = os.getenv(\"TRAINING_DATA_CONTAINER_NAME\")\n",
    "#     if not TRAINING_DATA_STORAGE_ACCOUNT_NAME:\n",
    "#         raise ValueError(\n",
    "#             \"Please set either TRAINING_DATA_SAS_URL or both TRAINING_DATA_STORAGE_ACCOUNT_NAME \"\n",
    "#             \"and TRAINING_DATA_CONTAINER_NAME environment variables.\"\n",
    "#         )\n",
    "#     training_data_sas_url = AzureContentUnderstandingClient.generate_temp_container_sas_url(\n",
    "#         account_name=TRAINING_DATA_STORAGE_ACCOUNT_NAME,\n",
    "#         container_name=TRAINING_DATA_CONTAINER_NAME,\n",
    "#         permissions=ContainerSasPermissions(read=True, write=True, list=True),\n",
    "#         expiry_hours=1,\n",
    "#     )\n",
    "\n",
    "# training_data_path = os.getenv(\"TRAINING_DATA_PATH\")\n",
    "\n",
    "# # Upload training data to blob storage\n",
    "# print(\"Uploading training data to blob storage...\")\n",
    "# await client.generate_training_data_on_blob(training_docs_folder, training_data_sas_url, training_data_path)\n",
    "# print(\"âœ… Training data uploaded successfully!\")\n",
    "\n",
    "# # Create source analyzer\n",
    "# SOURCE_ANALYZER_ID = \"source-analyzer-\" + str(uuid.uuid4())\n",
    "# print(f\"Creating source analyzer: {SOURCE_ANALYZER_ID}\")\n",
    "\n",
    "# response = client.begin_create_analyzer(\n",
    "#     SOURCE_ANALYZER_ID,\n",
    "#     analyzer_template_path=analyzer_template_path,\n",
    "#     training_storage_container_sas_url=training_data_sas_url,\n",
    "#     training_storage_container_path_prefix=training_data_path,\n",
    "# )\n",
    "# result = client.poll_result(response)\n",
    "# print(\"âœ… Source analyzer created successfully!\")\n",
    "# print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1bc93",
   "metadata": {},
   "source": [
    "## Step 3: Retrieve Source Analyzer Details\n",
    "\n",
    "Now we'll fetch the complete definition of the source analyzer, including its training data configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2c9ae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Analyzer: invoiceLabeledData\n",
      "Name: N/A\n",
      "Description: \n",
      "\n",
      "Full analyzer definition:\n",
      "{\n",
      "  \"analyzerId\": \"invoiceLabeledData\",\n",
      "  \"description\": \"\",\n",
      "  \"tags\": {\n",
      "    \"projectId\": \"d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb\",\n",
      "    \"templateId\": \"document-2025-05-01\"\n",
      "  },\n",
      "  \"createdAt\": \"2025-10-22T22:03:08Z\",\n",
      "  \"lastModifiedAt\": \"2025-10-22T22:03:11Z\",\n",
      "  \"baseAnalyzerId\": \"prebuilt-documentAnalyzer\",\n",
      "  \"config\": {\n",
      "    \"returnDetails\": true,\n",
      "    \"enableOcr\": true,\n",
      "    \"enableLayout\": true,\n",
      "    \"enableFormula\": false,\n",
      "    \"disableContentFiltering\": false,\n",
      "    \"tableFormat\": \"html\",\n",
      "    \"estimateFieldSourceAndConfidence\": false\n",
      "  },\n",
      "  \"fieldSchema\": {\n",
      "    \"fields\": {\n",
      "      \"CompanyName\": {\n",
      "        \"type\": \"string\",\n",
      "        \"method\": \"extract\",\n",
      "        \"description\": \"Name of the pharmaceutical company involved in the rebate program\"\n",
      "      },\n",
      "      \"ProductDetails\": {\n",
      "        \"type\": \"array\",\n",
      "        \"description\": \"List of products with rebate and unit details\",\n",
      "        \"items\": {\n",
      "          \"type\": \"object\",\n",
      "          \"description\": \"Details of a single product\",\n",
      "          \"properties\": {\n",
      "            \"ProductPackageCode\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Code representing the product or package\"\n",
      "            },\n",
      "            \"ProductName\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Name of the product\"\n",
      "            },\n",
      "            \"FfsimcoRecordId\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Record ID for FFSIMCO\"\n",
      "            },\n",
      "            \"RebatePerUnit\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Rebate amount per unit of the product\"\n",
      "            },\n",
      "            \"AdjustedRebatePerUnit\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Adjusted rebate amount per unit\"\n",
      "            },\n",
      "            \"UnitsInvoiced\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Number of units invoiced\"\n",
      "            },\n",
      "            \"UnitsPaid\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Number of units for which payment was made\"\n",
      "            },\n",
      "            \"RebateAmountInvoiced\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Total rebate amount invoiced\"\n",
      "            },\n",
      "            \"RebateAmountPaid\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Total rebate amount paid\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"TotalPaid\": {\n",
      "        \"type\": \"number\",\n",
      "        \"method\": \"extract\",\n",
      "        \"description\": \"Total payment amount \"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"trainingData\": {\n",
      "    \"containerUrl\": \"https://staistudiote203841201294.blob.core.windows.net/7c123b64-9378-4fa7-a807-081efa839c00-cu\",\n",
      "    \"kind\": \"blob\",\n",
      "    \"prefix\": \"labelingProjects/d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb/train\"\n",
      "  },\n",
      "  \"warnings\": [],\n",
      "  \"status\": \"ready\",\n",
      "  \"processingLocation\": \"geography\",\n",
      "  \"mode\": \"standard\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get detailed information about the source analyzer\n",
    "source_analyzer = client.get_analyzer_detail_by_id(SOURCE_ANALYZER_ID)\n",
    "\n",
    "print(f\"Source Analyzer: {SOURCE_ANALYZER_ID}\")\n",
    "print(f\"Name: {source_analyzer.get('name', 'N/A')}\")\n",
    "print(f\"Description: {source_analyzer.get('description', 'N/A')}\")\n",
    "print(\"\\nFull analyzer definition:\")\n",
    "print(json.dumps(source_analyzer, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0b65d",
   "metadata": {},
   "source": [
    "## Step 4: Extract Training Data Configuration\n",
    "\n",
    "Extract the training data configuration from the source analyzer. This includes:\n",
    "- **trainingData**: The blob container location with labeled examples\n",
    "- **fieldSchema**: The field definitions\n",
    "- **tags**: Project and template metadata (important for Azure AI Foundry project association)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c57655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Training Data Configuration:\n",
      "{\n",
      "  \"containerUrl\": \"https://staistudiote203841201294.blob.core.windows.net/7c123b64-9378-4fa7-a807-081efa839c00-cu\",\n",
      "  \"kind\": \"blob\",\n",
      "  \"prefix\": \"labelingProjects/d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb/train\"\n",
      "}\n",
      "\n",
      "âœ… Found training data at: https://staistudiote203841201294.blob.core.windows.net/7c123b64-9378-4fa7-a807-081efa839c00-cu\n",
      "   Path prefix: labelingProjects/d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb/train\n",
      "\n",
      "ðŸ“š Knowledge Sources Configuration:\n",
      "No knowledge sources configured (this is normal for standard mode)\n",
      "\n",
      "ðŸ“‹ Field Schema:\n",
      "{\n",
      "  \"fields\": {\n",
      "    \"CompanyName\": {\n",
      "      \"type\": \"string\",\n",
      "      \"method\": \"extract\",\n",
      "      \"description\": \"Name of the pharmaceutical company involved in the rebate program\"\n",
      "    },\n",
      "    \"ProductDetails\": {\n",
      "      \"type\": \"array\",\n",
      "      \"description\": \"List of products with rebate and unit details\",\n",
      "      \"items\": {\n",
      "        \"type\": \"object\",\n",
      "        \"description\": \"Details of a single product\",\n",
      "        \"properties\": {\n",
      "          \"ProductPackageCode\": {\n",
      "            \"type\": \"string\",\n",
      "            \"method\": \"extract\",\n",
      "            \"description\": \"Code representing the product or package\"\n",
      "          },\n",
      "          \"ProductName\": {\n",
      "            \"type\": \"string\",\n",
      "            \"method\": \"extract\",\n",
      "            \"description\": \"Name of the product\"\n",
      "          },\n",
      "          \"FfsimcoRecordId\": {\n",
      "            \"type\": \"string\",\n",
      "            \"method\": \"extract\",\n",
      "            \"description\": \"Record ID for FFSIMCO\"\n",
      "          },\n",
      "          \"RebatePerUnit\": {\n",
      "            \"type\": \"number\",\n",
      "            \"method\": \"extract\",\n",
      "            \"description\": \"Rebate amount per unit of the product\"\n",
      "          },\n",
      "          \"AdjustedRebatePerUnit\": {\n",
      "            \"type\": \"number\",\n",
      "            \"method\": \"extract\",\n",
      "            \"description\": \"Adjusted rebate amount per unit\"\n",
      "          },\n",
      "          \"UnitsInvoiced\": {\n",
      "            \"type\": \"number\",\n",
      "            \"method\": \"extract\",\n",
      "            \"description\": \"Number of units invoiced\"\n",
      "          },\n",
      "          \"UnitsPaid\": {\n",
      "            \"type\": \"number\",\n",
      "            \"method\": \"extract\",\n",
      "            \"description\": \"Number of units for which payment was made\"\n",
      "          },\n",
      "          \"RebateAmountInvoiced\": {\n",
      "            \"type\": \"number\",\n",
      "            \"method\": \"extract\",\n",
      "            \"description\": \"Total rebate amount invoiced\"\n",
      "          },\n",
      "          \"RebateAmountPaid\": {\n",
      "            \"type\": \"number\",\n",
      "            \"method\": \"extract\",\n",
      "            \"description\": \"Total rebate amount paid\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"TotalPaid\": {\n",
      "      \"type\": \"number\",\n",
      "      \"method\": \"extract\",\n",
      "      \"description\": \"Total payment amount \"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "ðŸ·ï¸  Tags (Project & Template Metadata):\n",
      "{\n",
      "  \"projectId\": \"d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb\",\n",
      "  \"templateId\": \"document-2025-05-01\"\n",
      "}\n",
      "\n",
      "âœ… Found Project ID: d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb\n",
      "âœ… Found Template ID: document-2025-05-01\n",
      "\n",
      "ðŸ’¡ These tags will be copied to ensure the new analyzer appears in the same Azure AI Foundry project.\n"
     ]
    }
   ],
   "source": [
    "# Extract training data configuration\n",
    "training_data_config = source_analyzer.get('trainingData')\n",
    "knowledge_sources_config = source_analyzer.get('knowledgeSources')\n",
    "field_schema = source_analyzer.get('fieldSchema', {})\n",
    "tags = source_analyzer.get('tags', {})\n",
    "\n",
    "print(\"ðŸ“¦ Training Data Configuration:\")\n",
    "if training_data_config:\n",
    "    print(json.dumps(training_data_config, indent=2))\n",
    "    container_url = training_data_config.get('containerUrl', 'N/A')\n",
    "    prefix = training_data_config.get('prefix', '')\n",
    "    print(f\"\\nâœ… Found training data at: {container_url}\")\n",
    "    print(f\"   Path prefix: {prefix}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No training data found in this analyzer.\")\n",
    "    print(\"   Please select an analyzer that has training data configured.\")\n",
    "\n",
    "print(\"\\nðŸ“š Knowledge Sources Configuration:\")\n",
    "if knowledge_sources_config:\n",
    "    print(json.dumps(knowledge_sources_config, indent=2))\n",
    "else:\n",
    "    print(\"No knowledge sources configured (this is normal for standard mode)\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Field Schema:\")\n",
    "print(json.dumps(field_schema, indent=2))\n",
    "\n",
    "print(\"\\nðŸ·ï¸  Tags (Project & Template Metadata):\")\n",
    "if tags:\n",
    "    print(json.dumps(tags, indent=2))\n",
    "    project_id = tags.get('projectId')\n",
    "    template_id = tags.get('templateId')\n",
    "    if project_id:\n",
    "        print(f\"\\nâœ… Found Project ID: {project_id}\")\n",
    "    if template_id:\n",
    "        print(f\"âœ… Found Template ID: {template_id}\")\n",
    "    print(\"\\nðŸ’¡ These tags will be copied to ensure the new analyzer appears in the same Azure AI Foundry project.\")\n",
    "else:\n",
    "    print(\"No tags found (the new analyzer may not be associated with a Foundry project)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7770461",
   "metadata": {},
   "source": [
    "## Step 5: Create New Analyzer with Existing Training Data\n",
    "\n",
    "Now we'll create a new analyzer that references the same training data. This new analyzer will:\n",
    "- Use the same blob storage container and path\n",
    "- Start with the same field schema (you can modify this)\n",
    "- Have its own unique ID\n",
    "- **Include the same tags** (projectId and templateId) to ensure it appears in the correct Azure AI Foundry project\n",
    "\n",
    "### Key Points:\n",
    "- **Same resource**: Both analyzers are in the same Azure AI resource\n",
    "- **No data duplication**: The training data stays in one place\n",
    "- **Same project**: Tags ensure the analyzer appears in the same Foundry project\n",
    "- **Independent lifecycle**: Each analyzer can be updated or deleted independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98b0c9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Including tags from source analyzer (ensures correct project association in Foundry)\n",
      "   Project ID: d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb\n",
      "   Template ID: document-2025-05-01\n",
      "\n",
      "Creating new analyzer: cloned-analyzer-c073f24d-5659-42ed-8ac8-b083bde79a9b\n",
      "\n",
      "New analyzer payload (ordered to match API structure):\n",
      "{\n",
      "  \"description\": \"Created from invoiceLabeledData with reused training data\",\n",
      "  \"tags\": {\n",
      "    \"projectId\": \"d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb\",\n",
      "    \"templateId\": \"document-2025-05-01\"\n",
      "  },\n",
      "  \"baseAnalyzerId\": \"prebuilt-documentAnalyzer\",\n",
      "  \"config\": {\n",
      "    \"returnDetails\": true,\n",
      "    \"enableOcr\": true,\n",
      "    \"enableLayout\": true,\n",
      "    \"enableFormula\": false,\n",
      "    \"disableContentFiltering\": false,\n",
      "    \"tableFormat\": \"html\",\n",
      "    \"estimateFieldSourceAndConfidence\": false\n",
      "  },\n",
      "  \"fieldSchema\": {\n",
      "    \"fields\": {\n",
      "      \"CompanyName\": {\n",
      "        \"type\": \"string\",\n",
      "        \"method\": \"extract\",\n",
      "        \"description\": \"Name of the pharmaceutical company involved in the rebate program\"\n",
      "      },\n",
      "      \"ProductDetails\": {\n",
      "        \"type\": \"array\",\n",
      "        \"description\": \"List of products with rebate and unit details\",\n",
      "        \"items\": {\n",
      "          \"type\": \"object\",\n",
      "          \"description\": \"Details of a single product\",\n",
      "          \"properties\": {\n",
      "            \"ProductPackageCode\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Code representing the product or package\"\n",
      "            },\n",
      "            \"ProductName\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Name of the product\"\n",
      "            },\n",
      "            \"FfsimcoRecordId\": {\n",
      "              \"type\": \"string\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Record ID for FFSIMCO\"\n",
      "            },\n",
      "            \"RebatePerUnit\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Rebate amount per unit of the product\"\n",
      "            },\n",
      "            \"AdjustedRebatePerUnit\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Adjusted rebate amount per unit\"\n",
      "            },\n",
      "            \"UnitsInvoiced\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Number of units invoiced\"\n",
      "            },\n",
      "            \"UnitsPaid\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Number of units for which payment was made\"\n",
      "            },\n",
      "            \"RebateAmountInvoiced\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Total rebate amount invoiced\"\n",
      "            },\n",
      "            \"RebateAmountPaid\": {\n",
      "              \"type\": \"number\",\n",
      "              \"method\": \"extract\",\n",
      "              \"description\": \"Total rebate amount paid\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"TotalPaid\": {\n",
      "        \"type\": \"number\",\n",
      "        \"method\": \"extract\",\n",
      "        \"description\": \"Total payment amount \"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"mode\": \"standard\"\n",
      "}\n",
      "\n",
      "ðŸ“¦ Training data will be configured separately:\n",
      "   Container URL: https://staistudiote203841201294.blob.core.windows.net/7c123b64-9378-4fa7-a807-081efa839c00-cu\n",
      "   Prefix: labelingProjects/d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb/train\n"
     ]
    }
   ],
   "source": [
    "# Verify we have training data before proceeding\n",
    "if not training_data_config:\n",
    "    raise ValueError(\n",
    "        \"Cannot proceed: Source analyzer does not have training data. \"\n",
    "        \"Please select an analyzer with training data or create one using the optional cell above.\"\n",
    "    )\n",
    "\n",
    "# Create a new analyzer ID\n",
    "# Analyzer names must be 1-64 characters and only contain letters, numbers, dots, underscores, or hyphens\n",
    "NEW_ANALYZER_ID = \"cloned-analyzer-\" + str(uuid.uuid4())\n",
    "\n",
    "# Build the new analyzer payload in the correct order matching the API structure\n",
    "# Note: Read-only fields like createdAt, lastModifiedAt, status, etc. are omitted as they're set by the service\n",
    "new_analyzer_payload = {}\n",
    "\n",
    "# 1. Analyzer ID (not needed as it's passed separately, but kept for reference)\n",
    "# new_analyzer_payload[\"analyzerId\"] = NEW_ANALYZER_ID\n",
    "\n",
    "# 2. Description\n",
    "new_analyzer_payload[\"description\"] = f\"Created from {SOURCE_ANALYZER_ID} with reused training data\"\n",
    "\n",
    "# 3. Tags (projectId and templateId) - IMPORTANT for Foundry project association\n",
    "if tags:\n",
    "    new_analyzer_payload[\"tags\"] = tags\n",
    "    print(\"âœ… Including tags from source analyzer (ensures correct project association in Foundry)\")\n",
    "    print(f\"   Project ID: {tags.get('projectId', 'N/A')}\")\n",
    "    print(f\"   Template ID: {tags.get('templateId', 'N/A')}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No tags found in source analyzer - new analyzer may not appear in Foundry project\")\n",
    "\n",
    "# 4. Base Analyzer ID (if present)\n",
    "if 'baseAnalyzerId' in source_analyzer:\n",
    "    new_analyzer_payload['baseAnalyzerId'] = source_analyzer['baseAnalyzerId']\n",
    "\n",
    "# 5. Config settings\n",
    "if 'config' in source_analyzer:\n",
    "    new_analyzer_payload['config'] = source_analyzer['config']\n",
    "\n",
    "# 6. Field Schema\n",
    "new_analyzer_payload[\"fieldSchema\"] = field_schema\n",
    "\n",
    "# 7. Training Data - Will be passed separately to begin_create_analyzer()\n",
    "# Note: We extract the container URL and prefix to pass as separate parameters\n",
    "training_container_sas_url = training_data_config.get('containerUrl', '')\n",
    "training_container_prefix = training_data_config.get('prefix', '')\n",
    "\n",
    "# 8. Knowledge Sources (if present - typically for Pro mode)\n",
    "# Extract these separately if they exist\n",
    "pro_mode_container_sas_url = \"\"\n",
    "pro_mode_container_prefix = \"\"\n",
    "if knowledge_sources_config and isinstance(knowledge_sources_config, list) and len(knowledge_sources_config) > 0:\n",
    "    # Get the first knowledge source (typically there's only one)\n",
    "    first_knowledge_source = knowledge_sources_config[0]\n",
    "    pro_mode_container_sas_url = first_knowledge_source.get('containerUrl', '')\n",
    "    pro_mode_container_prefix = first_knowledge_source.get('prefix', '')\n",
    "\n",
    "# 9. Mode (if present)\n",
    "if 'mode' in source_analyzer:\n",
    "    new_analyzer_payload['mode'] = source_analyzer['mode']\n",
    "\n",
    "print(f\"\\nCreating new analyzer: {NEW_ANALYZER_ID}\")\n",
    "print(\"\\nNew analyzer payload (ordered to match API structure):\")\n",
    "print(json.dumps(new_analyzer_payload, indent=2))\n",
    "\n",
    "print(\"\\nðŸ“¦ Training data will be configured separately:\")\n",
    "print(f\"   Container URL: {training_container_sas_url}\")\n",
    "print(f\"   Prefix: {training_container_prefix}\")\n",
    "\n",
    "if pro_mode_container_sas_url:\n",
    "    print(\"\\nðŸ“š Pro mode reference docs will be configured separately:\")\n",
    "    print(f\"   Container URL: {pro_mode_container_sas_url}\")\n",
    "    print(f\"   Prefix: {pro_mode_container_prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "385a0867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:python.content_understanding_client:Analyzer cloned-analyzer-c073f24d-5659-42ed-8ac8-b083bde79a9b create request accepted.\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request a22ddf12-3156-4a9a-9675-7b85789a8686 in progress ...\n",
      "INFO:python.content_understanding_client:Request result is ready after 152.25 seconds.\n",
      "INFO:python.content_understanding_client:Request result is ready after 152.25 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully created new analyzer: cloned-analyzer-c073f24d-5659-42ed-8ac8-b083bde79a9b\n",
      "\n",
      "Creation result:\n",
      "{\n",
      "  \"id\": \"a22ddf12-3156-4a9a-9675-7b85789a8686\",\n",
      "  \"status\": \"Succeeded\",\n",
      "  \"result\": {\n",
      "    \"analyzerId\": \"cloned-analyzer-c073f24d-5659-42ed-8ac8-b083bde79a9b\",\n",
      "    \"description\": \"Created from invoiceLabeledData with reused training data\",\n",
      "    \"tags\": {\n",
      "      \"projectId\": \"d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb\",\n",
      "      \"templateId\": \"document-2025-05-01\"\n",
      "    },\n",
      "    \"createdAt\": \"2025-10-22T22:44:56Z\",\n",
      "    \"lastModifiedAt\": \"2025-10-22T22:47:27Z\",\n",
      "    \"baseAnalyzerId\": \"prebuilt-documentAnalyzer\",\n",
      "    \"config\": {\n",
      "      \"returnDetails\": true,\n",
      "      \"enableOcr\": true,\n",
      "      \"enableLayout\": true,\n",
      "      \"enableFormula\": false,\n",
      "      \"disableContentFiltering\": false,\n",
      "      \"tableFormat\": \"html\",\n",
      "      \"estimateFieldSourceAndConfidence\": false\n",
      "    },\n",
      "    \"fieldSchema\": {\n",
      "      \"fields\": {\n",
      "        \"CompanyName\": {\n",
      "          \"type\": \"string\",\n",
      "          \"method\": \"extract\",\n",
      "          \"description\": \"Name of the pharmaceutical company involved in the rebate program\"\n",
      "        },\n",
      "        \"ProductDetails\": {\n",
      "          \"type\": \"array\",\n",
      "          \"description\": \"List of products with rebate and unit details\",\n",
      "          \"items\": {\n",
      "            \"type\": \"object\",\n",
      "            \"description\": \"Details of a single product\",\n",
      "            \"properties\": {\n",
      "              \"ProductPackageCode\": {\n",
      "                \"type\": \"string\",\n",
      "                \"method\": \"extract\",\n",
      "                \"description\": \"Code representing the product or package\"\n",
      "              },\n",
      "              \"ProductName\": {\n",
      "                \"type\": \"string\",\n",
      "                \"method\": \"extract\",\n",
      "                \"description\": \"Name of the product\"\n",
      "              },\n",
      "              \"FfsimcoRecordId\": {\n",
      "                \"type\": \"string\",\n",
      "                \"method\": \"extract\",\n",
      "                \"description\": \"Record ID for FFSIMCO\"\n",
      "              },\n",
      "              \"RebatePerUnit\": {\n",
      "                \"type\": \"number\",\n",
      "                \"method\": \"extract\",\n",
      "                \"description\": \"Rebate amount per unit of the product\"\n",
      "              },\n",
      "              \"AdjustedRebatePerUnit\": {\n",
      "                \"type\": \"number\",\n",
      "                \"method\": \"extract\",\n",
      "                \"description\": \"Adjusted rebate amount per unit\"\n",
      "              },\n",
      "              \"UnitsInvoiced\": {\n",
      "                \"type\": \"number\",\n",
      "                \"method\": \"extract\",\n",
      "                \"description\": \"Number of units invoiced\"\n",
      "              },\n",
      "              \"UnitsPaid\": {\n",
      "                \"type\": \"number\",\n",
      "                \"method\": \"extract\",\n",
      "                \"description\": \"Number of units for which payment was made\"\n",
      "              },\n",
      "              \"RebateAmountInvoiced\": {\n",
      "                \"type\": \"number\",\n",
      "                \"method\": \"extract\",\n",
      "                \"description\": \"Total rebate amount invoiced\"\n",
      "              },\n",
      "              \"RebateAmountPaid\": {\n",
      "                \"type\": \"number\",\n",
      "                \"method\": \"extract\",\n",
      "                \"description\": \"Total rebate amount paid\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"TotalPaid\": {\n",
      "          \"type\": \"number\",\n",
      "          \"method\": \"extract\",\n",
      "          \"description\": \"Total payment amount \"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"trainingData\": {\n",
      "      \"containerUrl\": \"https://staistudiote203841201294.blob.core.windows.net/7c123b64-9378-4fa7-a807-081efa839c00-cu\",\n",
      "      \"kind\": \"blob\",\n",
      "      \"prefix\": \"labelingProjects/d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb/train/\"\n",
      "    },\n",
      "    \"warnings\": [],\n",
      "    \"status\": \"ready\",\n",
      "    \"processingLocation\": \"geography\",\n",
      "    \"mode\": \"standard\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create the new analyzer\n",
    "# Pass training data and knowledge sources as separate parameters\n",
    "response = client.begin_create_analyzer(\n",
    "    NEW_ANALYZER_ID,\n",
    "    analyzer_template=new_analyzer_payload,\n",
    "    training_storage_container_sas_url=training_container_sas_url,\n",
    "    training_storage_container_path_prefix=training_container_prefix,\n",
    ")\n",
    "\n",
    "result = client.poll_result(response)\n",
    "\n",
    "if result and result.get('status') == 'Succeeded':\n",
    "    print(f\"âœ… Successfully created new analyzer: {NEW_ANALYZER_ID}\")\n",
    "    print(\"\\nCreation result:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "else:\n",
    "    print(\"âš ï¸ Analyzer creation encountered an issue.\")\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63295659",
   "metadata": {},
   "source": [
    "## Step 6: Verify the New Analyzer\n",
    "\n",
    "Let's confirm the new analyzer was created correctly and is using the same training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "685ff06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Analyzer: cloned-analyzer-c073f24d-5659-42ed-8ac8-b083bde79a9b\n",
      "Name: N/A\n",
      "Description: Created from invoiceLabeledData with reused training data\n",
      "\n",
      "Training Data Configuration:\n",
      "{\n",
      "  \"containerUrl\": \"https://staistudiote203841201294.blob.core.windows.net/7c123b64-9378-4fa7-a807-081efa839c00-cu\",\n",
      "  \"kind\": \"blob\",\n",
      "  \"prefix\": \"labelingProjects/d7afeaa4-fe05-4df7-bd7c-46f3a94a96cb/train/\"\n",
      "}\n",
      "\n",
      "âœ… Verification successful: Both analyzers reference the same training data location!\n"
     ]
    }
   ],
   "source": [
    "# Get details of the newly created analyzer\n",
    "new_analyzer = client.get_analyzer_detail_by_id(NEW_ANALYZER_ID)\n",
    "\n",
    "print(f\"New Analyzer: {NEW_ANALYZER_ID}\")\n",
    "print(f\"Name: {new_analyzer.get('name', 'N/A')}\")\n",
    "print(f\"Description: {new_analyzer.get('description', 'N/A')}\")\n",
    "print(\"\\nTraining Data Configuration:\")\n",
    "print(json.dumps(new_analyzer.get('trainingData', {}), indent=2))\n",
    "\n",
    "# Verify the training data location matches\n",
    "new_training_data = new_analyzer.get('trainingData', {})\n",
    "original_container = training_data_config.get('containerUrl', '')\n",
    "new_container = new_training_data.get('containerUrl', '')\n",
    "\n",
    "if original_container == new_container:\n",
    "    print(\"\\nâœ… Verification successful: Both analyzers reference the same training data location!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Warning: Training data locations don't match.\")\n",
    "    print(f\"Original: {original_container}\")\n",
    "    print(f\"New: {new_container}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3352c9",
   "metadata": {},
   "source": [
    "## Step 7: Test Both Analyzers\n",
    "\n",
    "Now let's test both analyzers with a sample file to verify they both work correctly with the shared training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc934efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with file: ../data/receipt.png\n"
     ]
    }
   ],
   "source": [
    "# Specify a test file - adjust this path based on your analyzer type\n",
    "# For receipt analyzers:\n",
    "test_file = \"../data/receipt.png\"\n",
    "\n",
    "# For invoice analyzers:\n",
    "# test_file = \"../data/invoice.pdf\"\n",
    "\n",
    "# For custom documents:\n",
    "# test_file = \"../data/your-document.pdf\"\n",
    "\n",
    "# Verify the file exists\n",
    "if not Path(test_file).exists():\n",
    "    print(f\"âš ï¸ Test file not found: {test_file}\")\n",
    "    print(\"Please adjust the test_file path to match your use case.\")\n",
    "else:\n",
    "    print(f\"Testing with file: {test_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "273dd85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Analyzing with SOURCE analyzer: invoiceLabeledData\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:python.content_understanding_client:Analyzing file ../data/receipt.png with analyzer: invoiceLabeledData\n",
      "INFO:python.content_understanding_client:Request 80b00372-a498-4564-9ff1-1e6901778a2d in progress ...\n",
      "INFO:python.content_understanding_client:Request 80b00372-a498-4564-9ff1-1e6901778a2d in progress ...\n",
      "INFO:python.content_understanding_client:Request 80b00372-a498-4564-9ff1-1e6901778a2d in progress ...\n",
      "INFO:python.content_understanding_client:Request 80b00372-a498-4564-9ff1-1e6901778a2d in progress ...\n",
      "INFO:python.content_understanding_client:Request result is ready after 4.71 seconds.\n",
      "INFO:python.content_understanding_client:Request result is ready after 4.71 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source Analyzer Results:\n",
      "Extracted 3 field(s)\n",
      "  - CompanyName: {'type': 'string', 'valueString': 'Contoso'}\n",
      "  - ProductDetails: {'type': 'array'}\n",
      "  - TotalPaid: {'type': 'number', 'valueNumber': 2516.28}\n"
     ]
    }
   ],
   "source": [
    "# Test the original analyzer\n",
    "if Path(test_file).exists():\n",
    "    print(f\"\\nðŸ“ Analyzing with SOURCE analyzer: {SOURCE_ANALYZER_ID}\")\n",
    "    response_source = client.begin_analyze(SOURCE_ANALYZER_ID, file_location=test_file)\n",
    "    result_source = client.poll_result(response_source)\n",
    "    \n",
    "    print(\"\\nSource Analyzer Results:\")\n",
    "    # Print a summary of extracted fields\n",
    "    if result_source.get('status') == 'Succeeded':\n",
    "        result_data = result_source.get('result', {})\n",
    "        fields = result_data.get('contents', [{}])[0].get('fields', {})\n",
    "        print(f\"Extracted {len(fields)} field(s)\")\n",
    "        for field_name, field_value in fields.items():\n",
    "            print(f\"  - {field_name}: {field_value}\")\n",
    "    else:\n",
    "        print(json.dumps(result_source, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9654313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Analyzing with NEW analyzer: cloned-analyzer-c073f24d-5659-42ed-8ac8-b083bde79a9b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:python.content_understanding_client:Analyzing file ../data/receipt.png with analyzer: cloned-analyzer-c073f24d-5659-42ed-8ac8-b083bde79a9b\n",
      "INFO:python.content_understanding_client:Request 5d982b83-4b1c-4e99-b045-48e36cb5a7e3 in progress ...\n",
      "INFO:python.content_understanding_client:Request 5d982b83-4b1c-4e99-b045-48e36cb5a7e3 in progress ...\n",
      "INFO:python.content_understanding_client:Request 5d982b83-4b1c-4e99-b045-48e36cb5a7e3 in progress ...\n",
      "INFO:python.content_understanding_client:Request 5d982b83-4b1c-4e99-b045-48e36cb5a7e3 in progress ...\n",
      "INFO:python.content_understanding_client:Request result is ready after 4.72 seconds.\n",
      "INFO:python.content_understanding_client:Request result is ready after 4.72 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Analyzer Results:\n",
      "Extracted 3 field(s)\n",
      "  - CompanyName: {'type': 'string', 'valueString': 'Contoso'}\n",
      "  - ProductDetails: {'type': 'array'}\n",
      "  - TotalPaid: {'type': 'number', 'valueNumber': 2516.28}\n",
      "\n",
      "âœ… Both analyzers successfully processed the file using the shared training data!\n"
     ]
    }
   ],
   "source": [
    "# Test the new analyzer\n",
    "if Path(test_file).exists():\n",
    "    print(f\"\\nðŸ“ Analyzing with NEW analyzer: {NEW_ANALYZER_ID}\")\n",
    "    response_new = client.begin_analyze(NEW_ANALYZER_ID, file_location=test_file)\n",
    "    result_new = client.poll_result(response_new)\n",
    "    \n",
    "    print(\"\\nNew Analyzer Results:\")\n",
    "    # Print a summary of extracted fields\n",
    "    if result_new.get('status') == 'Succeeded':\n",
    "        result_data = result_new.get('result', {})\n",
    "        fields = result_data.get('contents', [{}])[0].get('fields', {})\n",
    "        print(f\"Extracted {len(fields)} field(s)\")\n",
    "        for field_name, field_value in fields.items():\n",
    "            print(f\"  - {field_name}: {field_value}\")\n",
    "    else:\n",
    "        print(json.dumps(result_new, indent=2))\n",
    "    \n",
    "    print(\"\\nâœ… Both analyzers successfully processed the file using the shared training data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913b6dd",
   "metadata": {},
   "source": [
    "## Step 8: Compare Results (Optional)\n",
    "\n",
    "Let's compare the full results from both analyzers side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6467b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(test_file).exists():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SOURCE ANALYZER FULL RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(json.dumps(result_source, indent=2))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"NEW ANALYZER FULL RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(json.dumps(result_new, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65f05c",
   "metadata": {},
   "source": [
    "## Step 9: Cleanup (Optional)\n",
    "\n",
    "If you want to clean up the test analyzers, you can delete them. In production, you typically keep analyzers for reuse.\n",
    "\n",
    "âš ï¸ **Warning**: This will permanently delete the analyzer. The training data in blob storage will remain unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cde3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete the new analyzer\n",
    "# print(f\"Deleting new analyzer: {NEW_ANALYZER_ID}\")\n",
    "# client.delete_analyzer(NEW_ANALYZER_ID)\n",
    "# print(\"âœ… New analyzer deleted\")\n",
    "\n",
    "# Uncomment to also delete the source analyzer (be careful!)\n",
    "# print(f\"Deleting source analyzer: {SOURCE_ANALYZER_ID}\")\n",
    "# client.delete_analyzer(SOURCE_ANALYZER_ID)\n",
    "# print(\"âœ… Source analyzer deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d952dfef",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "ðŸŽ‰ **Congratulations!** You have successfully:\n",
    "\n",
    "âœ… Retrieved an existing analyzer with training data  \n",
    "âœ… Extracted the training data configuration  \n",
    "âœ… Created a new analyzer referencing the same training data  \n",
    "âœ… Verified both analyzers work correctly  \n",
    "âœ… Tested both analyzers with a sample file  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **No data duplication**: Both analyzers reference the same blob storage location\n",
    "- **Same resource**: Both analyzers use the same authentication and access permissions\n",
    "- **Field portability**: You can maintain stable `fieldId`s across different analyzer versions\n",
    "- **Rapid iteration**: Test schema changes quickly without re-uploading training data\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Stable field IDs**: Keep `fieldId`s consistent across analyzers for easier migration\n",
    "2. **Version control**: Maintain analyzer schemas in source control\n",
    "3. **Documentation**: Document which blob paths contain which training datasets\n",
    "4. **Testing**: Always test a new analyzer before deleting the original\n",
    "5. **Naming conventions**: Use descriptive analyzer IDs that indicate purpose and version\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Modify the field schema in the new analyzer to test different configurations\n",
    "- Add additional training data to improve both analyzers\n",
    "- Use this pattern to create A/B testing scenarios\n",
    "- Explore other notebooks:\n",
    "  - [analyzer_training.ipynb](./analyzer_training.ipynb) - Create analyzers with training data\n",
    "  - [field_extraction.ipynb](./field_extraction.ipynb) - Extract fields from documents\n",
    "  - [management.ipynb](./management.ipynb) - Manage analyzer lifecycle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
